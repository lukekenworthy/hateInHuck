{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "c3824052-b08c-4dc7-863b-187dd53c8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42d4ae7-05b9-4a54-a81a-d9ca128771e4",
   "metadata": {},
   "source": [
    "First, build a data table linking file ids to their label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "1dbe855d-7c67-40bb-82e0-8761a8625b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>subforum_id</th>\n",
       "      <th>num_contexts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12834217_1</th>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834217_2</th>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834217_3</th>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834217_4</th>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12834217_5</th>\n",
       "      <td>572066</td>\n",
       "      <td>1346</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33676864_5</th>\n",
       "      <td>734541</td>\n",
       "      <td>1388</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33677019_1</th>\n",
       "      <td>735154</td>\n",
       "      <td>1388</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33677019_2</th>\n",
       "      <td>735154</td>\n",
       "      <td>1388</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33677053_1</th>\n",
       "      <td>572266</td>\n",
       "      <td>1388</td>\n",
       "      <td>0</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33677053_2</th>\n",
       "      <td>572266</td>\n",
       "      <td>1388</td>\n",
       "      <td>0</td>\n",
       "      <td>noHate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10944 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id  subforum_id  num_contexts   label\n",
       "file_id                                               \n",
       "12834217_1   572066         1346             0  noHate\n",
       "12834217_2   572066         1346             0  noHate\n",
       "12834217_3   572066         1346             0  noHate\n",
       "12834217_4   572066         1346             0    hate\n",
       "12834217_5   572066         1346             0  noHate\n",
       "...             ...          ...           ...     ...\n",
       "33676864_5   734541         1388             0  noHate\n",
       "33677019_1   735154         1388             0  noHate\n",
       "33677019_2   735154         1388             0  noHate\n",
       "33677053_1   572266         1388             0    hate\n",
       "33677053_2   572266         1388             0  noHate\n",
       "\n",
       "[10944 rows x 4 columns]"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations = pd.read_csv(\"annotations_metadata.csv\").set_index(\"file_id\")\n",
    "annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "0442bdc5-a31b-4515-855d-001fed9ff809",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = {\"file_id\": [], \"text\": []}\n",
    "for path, name, filenames in os.walk(\"all_files\"):\n",
    "    for filename in filenames:\n",
    "        full_name = path + \"/\" + filename\n",
    "        file_id = filename.split(\".\")[0]\n",
    "        df1[\"file_id\"].append(file_id)\n",
    "        with open(full_name) as f:\n",
    "            text = f.read()\n",
    "            df1[\"text\"].append(text)\n",
    "id_text = pd.DataFrame(df1).set_index(\"file_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "d8f9ad2c-0ce8-433d-94e0-63e3924dc93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xy_pre = id_text.join(annotations).drop(columns=[\"user_id\", \"subforum_id\", \"num_contexts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "3b84bb09-f992-4b40-8bb9-a639ebfff497",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(\"labeled_data.csv\")\n",
    "tweets[\"label\"] = tweets.apply(lambda row: \"hate\" if row[\"hate_speech\"] > row[\"count\"] // 2 else \"noHate\", axis=1)\n",
    "tweets[\"text\"] = tweets[\"tweet\"]\n",
    "tweets_dropped = tweets.drop(columns=[\"Unnamed: 0\", \"count\", \"hate_speech\", \"offensive_language\", \"neither\", \"class\", \"tweet\"])\n",
    "\n",
    "Xy = tweets_dropped.append(Xy_pre)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791780b1-c6dd-473f-a4d4-5b33065cbf2d",
   "metadata": {},
   "source": [
    "Some code borrowed from: https://thecleverprogrammer.com/2020/08/19/hate-speech-detection-model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "8bad7bcb-0a84-4509-879b-7d5cf4d0111c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noHate</td>\n",
       "      <td>rt  as a woman you shouldnt complain about cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>noHate</td>\n",
       "      <td>rt  boy dats coldtyga dwn bad for cuffin dat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>noHate</td>\n",
       "      <td>rt  dawg rt  you ever fuck a bitch and she st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>noHate</td>\n",
       "      <td>rt ganderson based she look like a tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>noHate</td>\n",
       "      <td>rt  the shit you hear about me might be true ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13472256_1</th>\n",
       "      <td>noHate</td>\n",
       "      <td>also it s so sad to see so much pre made crap ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14417873_2</th>\n",
       "      <td>noHate</td>\n",
       "      <td>cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30597853_3</th>\n",
       "      <td>noHate</td>\n",
       "      <td>sorry that you were unaware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30626265_1</th>\n",
       "      <td>noHate</td>\n",
       "      <td>my grandmother has red hair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14268621_1</th>\n",
       "      <td>noHate</td>\n",
       "      <td>when anyone is ready we are now taking reserva...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35486 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                               text\n",
       "0           noHate   rt  as a woman you shouldnt complain about cl...\n",
       "1           noHate   rt  boy dats coldtyga dwn bad for cuffin dat ...\n",
       "2           noHate   rt  dawg rt  you ever fuck a bitch and she st...\n",
       "3           noHate          rt ganderson based she look like a tranny\n",
       "4           noHate   rt  the shit you hear about me might be true ...\n",
       "...            ...                                                ...\n",
       "13472256_1  noHate  also it s so sad to see so much pre made crap ...\n",
       "14417873_2  noHate                                                 cf\n",
       "30597853_3  noHate                       sorry that you were unaware \n",
       "30626265_1  noHate                       my grandmother has red hair \n",
       "14268621_1  noHate  when anyone is ready we are now taking reserva...\n",
       "\n",
       "[35486 rows x 2 columns]"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def  clean_text(df, text_field):\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    df[text_field] = df[text_field].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))  \n",
    "    return df\n",
    "cleaned = clean_text(Xy, \"text\")\n",
    "cleaned = cleaned[(cleaned.label == \"hate\") | (cleaned.label == \"noHate\")]\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "ec373e91-1ed9-43f6-b45f-955c7b8f7473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "noHate    24695\n",
       "hate       1919\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 589,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xy_train, Xy_test = train_test_split(cleaned, random_state = 0)\n",
    "Xy_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "ab3ec50e-9577-417b-b1ef-0f2eede29a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "upsampling = True\n",
    "if upsampling:\n",
    "    train_hate = Xy_train[Xy_train.label==\"hate\"]\n",
    "    train_nohate = Xy_train[Xy_train.label==\"noHate\"]\n",
    "    train_hate_upsampled = resample(train_hate, \n",
    "                                     replace=True,    \n",
    "                                     n_samples=len(train_nohate),   \n",
    "                                     random_state=0)\n",
    "    train_upsampled = pd.concat([train_hate_upsampled, train_nohate])\n",
    "else:\n",
    "    train_upsampled = Xy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "92f18748-adac-4b46-acdc-3daf93408890",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "pipeline_sgd = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('nb', SGDClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "f806a706-8621-486d-b2dd-cec940cfa941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, y_train = train_upsampled[\"text\"], train_upsampled[\"label\"]\n",
    "X_test, y_test = Xy_test[\"text\"], Xy_test[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "17291e7c-5cdd-42ec-abd3-7977cdaa3413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8586564472497745\n",
      "f1 score 0.9197491360552925\n",
      "False positive rate = 0.38197424892703863\n",
      "False negative rate = 0.12076348953872507\n",
      "True positive rate (sensitivity)= 0.8792365104612749\n",
      "True negative rate (sensitivity)= 0.6180257510729614\n",
      "[[ 432  267]\n",
      " [ 987 7186]]\n"
     ]
    }
   ],
   "source": [
    "model = pipeline_sgd.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "print(model.score(X_test, y_test))\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "print(\"f1 score\", f1_score(y_test, y_predict, pos_label=\"noHate\"))\n",
    "\n",
    "matrix = confusion_matrix(y_test, y_predict, labels=[\"hate\", \"noHate\"])\n",
    "tn, fp, fn, tp = matrix.ravel()\n",
    "print(\"False positive rate =\", fp / (fp + tn))\n",
    "print(\"False negative rate =\", fn / (fn + tp))\n",
    "print(\"True positive rate (sensitivity)=\", tp / (tp + fn))\n",
    "print(\"True negative rate (sensitivity)=\", tn / (tn + fp))\n",
    "# print(\"False negative rate =\", fn / (fn + tn))\n",
    "print(matrix)\n",
    "# print(y_test[y_test == \"hate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "af527355-6205-4fd4-9ae4-7c183a2d9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassification(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
    "    return model.predict(pd.Series([text]))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0a9da9-a6b2-4719-b81f-fff9824a3df4",
   "metadata": {},
   "source": [
    "We went tiptoeing along a path amongst the trees back towards the end of the widow’s garden, stooping down so as the branches wouldn’t scrape our heads. When we was passing by the kitchen I fell over a root and made a noise. We scrouched down and laid still. Miss Watson’s big nigger, named Jim, was setting in the kitchen door; we could see him pretty clear, because there was a light behind him. He got up and stretched his neck out about a minute, listening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "444ec00e-c7f9-4c80-8f74-d8c55a64f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noHate We went tiptoeing along a path amongst the trees back towards the end of the widow’s garden, stooping down so as the branches wouldn’t scrape our heads\n",
      "\n",
      "noHate  When we was passing by the kitchen I fell over a root and made a noise\n",
      "\n",
      "noHate  We scrouched down and laid still\n",
      "\n",
      "noHate  Miss Watson’s big nigger, named Jim, was setting in the kitchen door; we could see him pretty clear, because there was a light behind him\n",
      "\n",
      "noHate  He got up and stretched his neck out about a minute, listening\n",
      "\n",
      "noHate \n",
      "\n"
     ]
    }
   ],
   "source": [
    "huckfinn = \"We went tiptoeing along a path amongst the trees back towards the end of the widow’s garden, stooping down so as the branches wouldn’t scrape our heads. When we was passing by the kitchen I fell over a root and made a noise. We scrouched down and laid still. Miss Watson’s big nigger, named Jim, was setting in the kitchen door; we could see him pretty clear, because there was a light behind him. He got up and stretched his neck out about a minute, listening.\"\n",
    "for text in huckfinn.split(\".\"):\n",
    "    val = getClassification(text)\n",
    "    print(val, text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "8a2528a9-0e10-4e74-a2aa-fd7631c1fff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hate'"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getClassification(\"Niggers would come miles to hear Jim tell about it, and he was more looked up to than any nigger in that country.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa87099-aa7f-40b8-9e51-cb38ce530b4e",
   "metadata": {},
   "source": [
    "Now, open up Huck Finn and start parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "ee9b0e0d-cd42-4a83-b76e-ab5c4c353ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "html = open('huckfinn.html')\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "9f402999-bebb-47de-8ff9-5b1cc5b3ed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentenceClass(text):\n",
    "    sentences = tokenize.sent_tokenize(text)\n",
    "    newSentences = []\n",
    "    for sentence in sentences:\n",
    "        label = getClassification(sentence)\n",
    "        newSentences.append((sentence.strip(), label))\n",
    "    return newSentences\n",
    "\n",
    "start = False\n",
    "starttext = \"You don’t know about me without you have read a book by the name of\"\n",
    "ctr = 0\n",
    "for p in soup.find_all('p'):\n",
    "    text = p.text\n",
    "    if starttext in text:\n",
    "        start = True\n",
    "    if start:\n",
    "        new_p = soup.new_tag(\"p\")\n",
    "        sentenceLabels = getSentenceClass(text)\n",
    "        for sentence, label in sentenceLabels:\n",
    "            span = soup.new_tag(\"span\")\n",
    "            span.string = sentence + \" \"\n",
    "            span[\"class\"] = label\n",
    "            new_p.append(span)\n",
    "        p.replace_with(new_p)\n",
    "        ctr += 1\n",
    "\n",
    "with open(\"modified_huck.html\", \"wb\") as f_output:\n",
    "    f_output.write(soup.prettify(\"utf-8\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800f21d-9c24-44e7-ba19-1adc4a71bf2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
